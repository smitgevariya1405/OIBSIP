# -*- coding: utf-8 -*-
"""Email Spam Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bdGtb9bK2VNnghhcMNwjI9ktccLmfpFE
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv("spam.csv",encoding="latin-1",usecols=["v1","v2"])
df
#So, when you specify encoding="latin-1" while reading a CSV file, you’re telling pandas to interpret the file using the latin-1 encoding. This can be necessary when your file contains characters that aren’t covered by the default encoding (which is usually UTF-8 in Python 3).

df.rename(columns={"v1":"Category","v2":"Message"},inplace=True)
df

df.head()

df.tail()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df["Category"]=le.fit_transform(df["Category"])
df

df.shape

df.info()

df.isnull().sum()

df.duplicated().sum()

df=df.drop_duplicates(keep="first")
df.duplicated().sum()

df.shape

df["Category"].value_counts()

plt.pie(df["Category"].value_counts(),autopct='%0.2f',labels=['Ham','Spam'])
plt.show()

class_counts=df["Category"].value_counts()
plt.bar(class_counts.index,class_counts.values,color=['red','Yellow'])
plt.xlabel("Class",fontsize=12)
plt.ylabel("Number of Messages",fontsize=12)
plt.title("Class Distributiion (spam vs ham)",fontsize=16)
plt.show()

from wordcloud import WordCloud,STOPWORDS
comment_words=''
stopwords=set(STOPWORDS)

for val in df.Message:
  val=str(val)
  tokens=val.split()

    # Converts each token into lowercase
  for i in range(len(tokens)):
    tokens[i]=tokens[i].lower()

  comment_words += "".join(tokens)+""

wordcloud=WordCloud(width=800,height=600,background_color='#f8f8ff',stopwords=stopwords,min_font_size=10).generate(comment_words)

"""from wordcloud import WordCloud, STOPWORDS: This line imports the WordCloud and STOPWORDS from the wordcloud module. WordCloud is a class for generating word clouds, and STOPWORDS is a set of commonly used words that you might want to exclude from your word cloud.



comment_words = '': This line initializes an empty string comment_words where the processed words from the messages will be stored.


stopwords = set(STOPWORDS): This line creates a set of stopwords that the WordCloud will ignore.


The for loop over df.Message: This loop goes through each message in the ‘Message’ column of the DataFrame df. It splits each message into words (tokens), converts each word to lowercase, and then adds them to the comment_words string.


wordcloud = WordCloud(width = 800, height = 600, background_color ='#f8f8ff', stopwords = stopwords, min_font_size = 10).generate(comment_words): This line generates the word cloud image. The width and height parameters specify the size of the image, background_color sets the background color of the image, stopwords specifies the words to be excluded from the image, and min_font_size sets the minimum font size of the words in the image.
So,

in simple words, this block of code is saying: “Create a word cloud image from the ‘Message’ column of my data table df, ignoring common words, and make the image 800 pixels wide and 600 pixels tall with a white background and a minimum font size of 10.”
"""

plt.figure(figsize=(5,5),facecolor=None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad=-5)
plt.show()

#plt.figure(figsize = (5,5), facecolor = None): This line creates a new figure for plotting. The figsize argument specifies the size of the figure in inches (width, height). The facecolor argument sets the background color of the figure. Here, it’s set to None, which means the default background color will be used.
#plt.imshow(wordcloud): This line displays the data in wordcloud as an image. The wordcloud variable is assumed to contain the data for a word cloud image.
#plt.axis("off"): This line turns off the axis lines and labels.
#plt.tight_layout(pad = 0): This line adjusts the parameters of the figure for it to fit into the figure area. The pad argument increases or decreases the padding around the figure border.

x=df['Message']
x

y=df['Category']
y

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

#from sklearn.feature_extraction.text import CountVectorizer: This line imports the CountVectorizer class from the sklearn.feature_extraction.text module. CountVectorizer is a class that converts a collection of text documents to a matrix of token counts.
#vectorizer.fit(x_train): This line fits the CountVectorizer instance to the x_train data. The fit method learns the vocabulary dictionary of all tokens in the raw documents.
#X_train_cv = vectorizer.transform(x_train): This line transforms the x_train data into a document-term matrix, where the entry of each cell will be the count of the number of times that word occurred in that document.
#X_test_cv = vectorizer.transform(x_test): This line transforms the x_test data into a document-term matrix using the same vocabulary as x_train.

from sklearn.feature_extraction.text import CountVectorizer
vectorizer=CountVectorizer()
vectorizer.fit(x_train)
x_train_cv=vectorizer.transform(x_train)
x_test_cv=vectorizer.transform(x_test)

from sklearn.linear_model import LogisticRegression
from sklearn import metrics

logreg=LogisticRegression()
logreg.fit(x_train_cv,y_train)

y_pred=logreg.predict(x_test_cv)
y_pred

y_test

print("Accuracy on  logistic regression classifier on test set:{:.2f}",format(logreg.score(x_test_cv,y_test)))

#from sklearn.metrics import confusion_matrix: This line imports the confusion_matrix function from the sklearn.metrics module. The confusion_matrix function is used to compute the confusion matrix to evaluate the accuracy of a classification.

from sklearn.metrics import confusion_matrix
confusion_matrix=confusion_matrix(y_test,y_pred)
confusion_matrix

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

#from sklearn.metrics import classification_report: This line imports the classification_report function from the sklearn.metrics module. The classification_report function builds a text report showing the main classification metrics.

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score

accuracy=accuracy_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 score:", f1)

from sklearn.naive_bayes import MultinomialNB
classifier=MultinomialNB()
classifier.fit(x_train_cv,y_train)

custom_word="i will call you later"
custom_word_vec=vectorizer.transform([custom_word])
prediction=classifier.predict(custom_word_vec)[0]

if prediction==1:
  prediction="Spam"
else:
  prediction="Ham"

print(f"custom word'{custom_word}'is predicted as :{prediction}")